"""Conversational AI client with history management for interactive course authoring."""

from typing import Dict, List, Generator, Optional
import anthropic

from src.config import Config


class AIClient:
    """Conversational AI client that maintains conversation history.

    Uses Anthropic Claude API for interactive course development workflows.
    Supports both streaming and non-streaming responses.
    """

    DEFAULT_SYSTEM_PROMPT = (
        "You are a helpful course authoring assistant specializing in "
        "Coursera short course development."
    )

    def __init__(self):
        """Initialize AI client with Anthropic API credentials.

        Raises:
            ValueError: If ANTHROPIC_API_KEY is not set in environment
        """
        if not Config.ANTHROPIC_API_KEY:
            raise ValueError(
                "ANTHROPIC_API_KEY not set. Copy .env.example to .env and add your key."
            )

        self.client = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY)
        self.model = Config.MODEL
        self.max_tokens = Config.MAX_TOKENS
        self.conversation_history: List[Dict[str, str]] = []

    def chat(
        self,
        user_message: str,
        system_prompt: Optional[str] = None
    ) -> str:
        """Send a message and get response, maintaining conversation history.

        Args:
            user_message: The user's message to send
            system_prompt: Optional system prompt (defaults to course authoring assistant)

        Returns:
            The assistant's response text

        Raises:
            anthropic.APIError: If API request fails
            anthropic.APIConnectionError: If connection to API fails
            anthropic.RateLimitError: If rate limit is exceeded
        """
        # Add user message to history
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        try:
            # Call API with history
            response = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                system=system_prompt or self.DEFAULT_SYSTEM_PROMPT,
                messages=self.conversation_history
            )

            # Extract response text
            assistant_message = response.content[0].text

            # Add assistant response to history
            self.conversation_history.append({
                "role": "assistant",
                "content": assistant_message
            })

            return assistant_message

        except Exception as e:
            # Remove user message from history on error
            self.conversation_history.pop()
            raise

    def chat_stream(
        self,
        user_message: str,
        system_prompt: Optional[str] = None
    ) -> Generator[str, None, None]:
        """Send a message and stream response chunks, maintaining history.

        Args:
            user_message: The user's message to send
            system_prompt: Optional system prompt

        Yields:
            Text chunks as they arrive from the API

        Raises:
            anthropic.APIError: If API request fails
            anthropic.APIConnectionError: If connection to API fails
            anthropic.RateLimitError: If rate limit is exceeded
        """
        # Add user message to history
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        full_response = []

        try:
            # Stream response
            with self.client.messages.stream(
                model=self.model,
                max_tokens=self.max_tokens,
                system=system_prompt or self.DEFAULT_SYSTEM_PROMPT,
                messages=self.conversation_history
            ) as stream:
                for text in stream.text_stream:
                    full_response.append(text)
                    yield text

            # Add complete response to history
            self.conversation_history.append({
                "role": "assistant",
                "content": "".join(full_response)
            })

        except Exception as e:
            # Remove user message from history on error
            self.conversation_history.pop()
            raise

    def generate(
        self,
        system_prompt: str,
        user_prompt: str,
        max_tokens: Optional[int] = None
    ) -> str:
        """Generate a one-shot response without polluting conversation history.

        Useful for batch operations or standalone generations that shouldn't
        affect the interactive conversation flow.

        Args:
            system_prompt: System instructions for the AI
            user_prompt: The user's prompt
            max_tokens: Optional token limit (defaults to Config.MAX_TOKENS)

        Returns:
            The assistant's response text

        Raises:
            anthropic.APIError: If API request fails
            anthropic.APIConnectionError: If connection to API fails
            anthropic.RateLimitError: If rate limit is exceeded
        """
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=max_tokens or self.max_tokens,
                system=system_prompt,
                messages=[{
                    "role": "user",
                    "content": user_prompt
                }]
            )

            return response.content[0].text

        except Exception as e:
            raise

    def clear_history(self):
        """Reset conversation history to empty state.

        Use this to start a fresh conversation or when switching contexts.
        """
        self.conversation_history = []
