---
phase: 02-course-management
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/core/models.py
  - app.py
  - tests/test_models.py
  - tests/test_app.py
autonomous: true

must_haves:
  truths:
    - "User can create a course with title, description, audience level, duration, modality, prerequisites, tools, and grading policy"
    - "User can edit all course metadata fields including new fields (prerequisites, tools, grading_policy)"
    - "User can view course list with status indicators (build state counts, module/lesson/activity counts)"
    - "User can delete a course"
  artifacts:
    - path: "src/core/models.py"
      provides: "Course model with prerequisites, tools, grading_policy fields"
      contains: "prerequisites"
    - path: "app.py"
      provides: "Enhanced CRUD endpoints with new fields and status indicators"
      contains: "prerequisites"
    - path: "tests/test_models.py"
      provides: "Round-trip tests for new Course fields"
      contains: "prerequisites"
    - path: "tests/test_app.py"
      provides: "API tests for enhanced CRUD and status indicators"
      contains: "status"
  key_links:
    - from: "app.py"
      to: "src/core/models.py"
      via: "Course constructor with new fields"
      pattern: "course\\.prerequisites"
---

<objective>
Extend the Course model with metadata fields required by COURSE-03 (prerequisites, tools, grading_policy) and enhance existing CRUD API endpoints to support all fields. Update list_courses() to include status indicators (build state counts, structure counts) for dashboard display.

Purpose: COURSE-01, COURSE-02, COURSE-03, COURSE-04 require full course metadata management and informative dashboard listing.
Output: Extended Course model, enhanced API endpoints, updated tests.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-course-management/02-RESEARCH.md
@src/core/models.py
@app.py
@tests/test_models.py
@tests/test_app.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend Course model with new metadata fields</name>
  <files>src/core/models.py, tests/test_models.py</files>
  <action>
Add three new Optional fields to the Course dataclass (after `modality` field, before `modules`):
- `prerequisites: Optional[str] = None` — text describing course prerequisites
- `tools: List[str] = field(default_factory=list)` — list of tools/software needed
- `grading_policy: Optional[str] = None` — grading policy description

Update Course.to_dict() to include the three new fields:
```python
"prerequisites": self.prerequisites,
"tools": self.tools,
"grading_policy": self.grading_policy,
```

Course.from_dict() already handles new fields via known-field filtering — no changes needed there.

Add tests in test_models.py:
1. Test Course with new fields serializes correctly via to_dict()
2. Test Course from_dict() round-trip with new fields preserves values
3. Test Course from_dict() with missing new fields defaults correctly (backward compat)
4. Test Course with tools list containing multiple items
  </action>
  <verify>Run `py -3 -m pytest tests/test_models.py -v` — all existing tests pass plus 4 new tests</verify>
  <done>Course dataclass has prerequisites (Optional[str]), tools (List[str]), grading_policy (Optional[str]) fields. Serialization round-trips work. Old JSON without these fields loads without error.</done>
</task>

<task type="auto">
  <name>Task 2: Enhance CRUD API and dashboard status indicators</name>
  <files>app.py, tests/test_app.py</files>
  <action>
1. Update create_course() endpoint to accept new fields:
   - `prerequisites` (optional string)
   - `tools` (optional list of strings)
   - `grading_policy` (optional string)

2. Update update_course() endpoint to handle new fields:
   ```python
   if 'prerequisites' in data:
       course.prerequisites = data['prerequisites']
   if 'tools' in data:
       course.tools = data['tools']
   if 'grading_policy' in data:
       course.grading_policy = data['grading_policy']
   ```

3. Update list_courses() in ProjectStore (or in the get_courses endpoint) to include richer status info. Modify the get_courses() endpoint to return additional fields:
   - `audience_level` — from course data
   - `modality` — from course data
   - `lesson_count` — sum of lessons across all modules
   - `activity_count` — sum of activities across all modules/lessons
   - `build_state` — overall course state: "empty" if no activities, "draft" if any activities exist but none generated, "in_progress" if some generated, "complete" if all approved/published
   - `target_duration_minutes` — from course data

   The list_courses() method in ProjectStore returns basic metadata. Enhance the API endpoint (not ProjectStore) by loading full course data for status computation, or add a helper. Keep it simple: update the dict returned in list_courses() to include these fields from the course JSON.

4. Add tests:
   - Test create course with prerequisites, tools, grading_policy
   - Test update course with new fields
   - Test list courses includes status fields (audience_level, modality, lesson_count, activity_count)
   - Test create course without new fields still works (backward compat)
  </action>
  <verify>Run `py -3 -m pytest tests/test_app.py -v` — all existing tests pass plus new tests</verify>
  <done>API accepts and persists all course metadata fields. Course list includes status indicators (audience_level, modality, lesson_count, activity_count, build_state). All tests pass.</done>
</task>

</tasks>

<verification>
```bash
py -3 -m pytest tests/test_models.py tests/test_app.py -v
```
All tests pass including new ones for extended fields and status indicators.
</verification>

<success_criteria>
- Course model has prerequisites, tools, grading_policy fields
- POST /api/courses accepts all metadata fields
- PUT /api/courses/<id> updates all metadata fields
- GET /api/courses returns status indicators per course
- All existing + new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-course-management/02-01-SUMMARY.md`
</output>
