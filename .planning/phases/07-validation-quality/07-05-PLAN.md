---
phase: 07-validation-quality
plan: 05
type: execute
wave: 3
depends_on: ["07-01", "07-02", "07-03", "07-04"]
files_modified:
  - src/validators/validation_report.py
  - src/api/validation.py
  - app.py
  - tests/test_validation_api.py
autonomous: true

must_haves:
  truths:
    - "User can view comprehensive validation report via API"
    - "Validation report aggregates results from all validators"
    - "is_publishable returns true only if no errors from any validator"
    - "Build state transition to PUBLISHED blocked if validation fails"
  artifacts:
    - path: "src/validators/validation_report.py"
      provides: "ValidationReport aggregator"
      exports: ["ValidationReport"]
    - path: "src/api/validation.py"
      provides: "Validation API Blueprint"
      exports: ["init_validation_bp", "validation_bp"]
    - path: "tests/test_validation_api.py"
      provides: "Validation API tests"
      min_lines: 60
  key_links:
    - from: "src/api/validation.py"
      to: "src/validators/validation_report.py"
      via: "import"
      pattern: "from src.validators.validation_report import ValidationReport"
    - from: "app.py"
      to: "src/api/validation.py"
      via: "blueprint registration"
      pattern: "init_validation_bp"
---

<objective>
Create ValidationReport aggregator, Validation API endpoints, and build state publishing gate.

Purpose: Implements QA-07 (view validation issues and warnings per course) and the build state gate preventing premature publishing. Aggregates all validators into a single report and provides API endpoints for validation.

Output: ValidationReport class, /api/courses/<id>/validate endpoint, build state gate on APPROVED -> PUBLISHED transition.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/07-validation-quality/07-RESEARCH.md
@.planning/phases/07-validation-quality/07-01-PLAN.md
@.planning/phases/07-validation-quality/07-02-PLAN.md
@.planning/phases/07-validation-quality/07-03-PLAN.md
@.planning/phases/07-validation-quality/07-04-PLAN.md
@src/validators/validation_result.py
@src/api/build_state.py
@app.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ValidationReport aggregator</name>
  <files>src/validators/validation_report.py</files>
  <action>
Create ValidationReport class that runs all validators and aggregates results:

```python
"""Aggregates all validation results into comprehensive report."""

from typing import Dict
from src.core.models import Course, ContentType
from src.validators.validation_result import ValidationResult
from src.validators.course_validator import CourseValidator
from src.validators.outcome_validator import OutcomeValidator
from src.validators.blooms_validator import BloomsValidator
from src.validators.distractor_validator import DistractorValidator
import json

class ValidationReport:
    """Aggregates all validation results into single report.

    Runs structural, outcome, Bloom's, and distractor validators.
    """

    def __init__(self):
        self.course_validator = CourseValidator()
        self.outcome_validator = OutcomeValidator()
        self.blooms_validator = BloomsValidator()
        self.distractor_validator = DistractorValidator()

    def validate_course(self, course: Course) -> Dict[str, ValidationResult]:
        """Run all validators and return combined report.

        Args:
            course: Course object to validate.

        Returns:
            Dict mapping validator name to ValidationResult.
        """
        results = {}

        # Run structural validation
        results["CourseValidator"] = self.course_validator.validate(course)

        # Run outcome validation
        results["OutcomeValidator"] = self.outcome_validator.validate(course)

        # Run Bloom's validation
        results["BloomsValidator"] = self.blooms_validator.validate(course)

        # Run distractor validation on all quiz activities
        distractor_result = self._validate_all_quizzes(course)
        results["DistractorValidator"] = distractor_result

        return results

    def is_publishable(self, course: Course) -> bool:
        """Check if course passes all critical validation checks.

        Only errors block publishing. Warnings are informational.

        Args:
            course: Course object to check.

        Returns:
            True if no errors from any validator.
        """
        results = self.validate_course(course)
        return all(result.is_valid for result in results.values())

    def _validate_all_quizzes(self, course: Course) -> ValidationResult:
        """Validate all quiz activities in course.

        Args:
            course: Course object to validate.

        Returns:
            Combined ValidationResult for all quizzes.
        """
        all_errors = []
        all_warnings = []
        all_suggestions = []
        total_quizzes = 0
        total_flagged = 0

        # Find all quiz activities
        for module in course.modules:
            for lesson in module.lessons:
                for activity in lesson.activities:
                    if activity.content_type == ContentType.QUIZ and activity.content:
                        total_quizzes += 1
                        result = self.distractor_validator.validate_quiz(activity.content)

                        # Prefix errors with activity title
                        for error in result.errors:
                            all_errors.append(f"[{activity.title}] {error}")
                        for warning in result.warnings:
                            all_warnings.append(f"[{activity.title}] {warning}")

                        if not result.is_valid:
                            total_flagged += 1

        if total_quizzes == 0:
            return ValidationResult(
                is_valid=True,
                errors=[],
                warnings=[],
                suggestions=["No quiz activities to validate"],
                metrics={"total_quizzes": 0}
            )

        quality_score = 1.0 - (total_flagged / total_quizzes) if total_quizzes > 0 else 0.0

        return ValidationResult(
            is_valid=len(all_errors) == 0,
            errors=all_errors,
            warnings=all_warnings,
            suggestions=all_suggestions,
            metrics={
                "total_quizzes": total_quizzes,
                "flagged_quizzes": total_flagged,
                "overall_quality_score": round(quality_score, 2)
            }
        )
```
  </action>
  <verify>python -c "from src.validators.validation_report import ValidationReport; print('ValidationReport imported')"</verify>
  <done>ValidationReport is importable with validate_course() and is_publishable() methods</done>
</task>

<task type="auto">
  <name>Task 2: Create Validation API Blueprint</name>
  <files>src/api/validation.py, app.py</files>
  <action>
Create validation API blueprint with /api/courses/<id>/validate endpoint:

```python
"""Validation API endpoints.

Provides endpoints for running course validation and viewing comprehensive reports.
"""

from flask import Blueprint, jsonify

from src.validators.validation_report import ValidationReport

# Create Blueprint
validation_bp = Blueprint('validation', __name__)

# Module-level references
_project_store = None
_validation_report = None


def init_validation_bp(project_store):
    """Initialize validation blueprint with dependencies.

    Args:
        project_store: ProjectStore instance for course loading.
    """
    global _project_store, _validation_report
    _project_store = project_store
    _validation_report = ValidationReport()


@validation_bp.route('/api/courses/<course_id>/validate', methods=['GET'])
def validate_course(course_id):
    """Run all validation checks and return comprehensive report.

    Args:
        course_id: Course identifier.

    Returns:
        JSON with:
        - is_publishable: bool (true if no errors)
        - validators: Dict of validator name -> result
        - summary: Aggregate counts

    Errors:
        404 if course not found.
        500 on validation error.
    """
    try:
        course = _project_store.load(course_id)
        if not course:
            return jsonify({"error": "Course not found"}), 404

        # Run all validators
        results = _validation_report.validate_course(course)
        is_publishable = _validation_report.is_publishable(course)

        # Convert ValidationResult objects to dicts
        results_dict = {
            name: result.to_dict()
            for name, result in results.items()
        }

        # Summary counts
        total_errors = sum(len(r.errors) for r in results.values())
        total_warnings = sum(len(r.warnings) for r in results.values())
        total_suggestions = sum(len(r.suggestions) for r in results.values())

        return jsonify({
            "is_publishable": is_publishable,
            "validators": results_dict,
            "summary": {
                "total_errors": total_errors,
                "total_warnings": total_warnings,
                "total_suggestions": total_suggestions
            }
        }), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500


@validation_bp.route('/api/courses/<course_id>/publishable', methods=['GET'])
def check_publishable(course_id):
    """Quick check if course is publishable.

    Args:
        course_id: Course identifier.

    Returns:
        JSON with:
        - is_publishable: bool
        - error_count: int

    Errors:
        404 if course not found.
    """
    try:
        course = _project_store.load(course_id)
        if not course:
            return jsonify({"error": "Course not found"}), 404

        results = _validation_report.validate_course(course)
        is_publishable = all(r.is_valid for r in results.values())
        error_count = sum(len(r.errors) for r in results.values())

        return jsonify({
            "is_publishable": is_publishable,
            "error_count": error_count
        }), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500
```

Then update app.py to register the validation blueprint:

1. Add import: `from src.api.validation import validation_bp, init_validation_bp`
2. After other blueprint initializations, add: `init_validation_bp(project_store)`
3. Register: `app.register_blueprint(validation_bp)`
  </action>
  <verify>python -c "from src.api.validation import validation_bp, init_validation_bp; print('validation_bp imported')"</verify>
  <done>Validation API blueprint created and registered in app.py</done>
</task>

<task type="auto">
  <name>Task 3: Add build state publishing gate</name>
  <files>src/api/build_state.py</files>
  <action>
Update the build_state.py to check validation before allowing APPROVED -> PUBLISHED transition:

1. Add import at top:
   ```python
   from src.validators.validation_report import ValidationReport
   ```

2. Add module-level ValidationReport:
   ```python
   _validation_report = None
   ```

3. Update init_build_state_bp to accept optional validation_report or create one:
   ```python
   def init_build_state_bp(project_store):
       global _project_store, _validation_report
       _project_store = project_store
       _validation_report = ValidationReport()
   ```

4. Update the state transition logic in update_state() function:
   After the existing `if not _is_valid_transition(current_state, target_state):` block, add a check for APPROVED -> PUBLISHED:

   ```python
   # Special validation gate for publishing
   if target_state == BuildState.PUBLISHED:
       if not _validation_report.is_publishable(course):
           return jsonify({
               "error": "Cannot publish: course has validation errors",
               "hint": "Run GET /api/courses/{id}/validate to see errors"
           }), 400
   ```

This ensures that no activity can transition to PUBLISHED if the course has validation errors.
  </action>
  <verify>python -c "from src.api.build_state import init_build_state_bp; print('build_state with gate imported')"</verify>
  <done>Build state API checks validation before allowing PUBLISHED transition</done>
</task>

<task type="auto">
  <name>Task 4: Add validation API tests</name>
  <files>tests/test_validation_api.py</files>
  <action>
Create tests for the validation API:

```python
"""Tests for validation API endpoints."""
import pytest
import json
from src.core.models import (
    Course, Module, Lesson, Activity, LearningOutcome,
    ContentType, BloomLevel, BuildState
)

@pytest.fixture
def valid_course(tmp_store):
    """Create a course that passes most validation."""
    course = Course(title="Valid Course", target_duration_minutes=60)

    # Add 2 modules with 3 lessons each, 2 activities each
    for m_idx in range(2):
        module = Module(title=f"Module {m_idx+1}")
        for l_idx in range(3):
            lesson = Lesson(title=f"Lesson {l_idx+1}")
            for a_idx in range(2):
                bloom = [BloomLevel.UNDERSTAND, BloomLevel.APPLY, BloomLevel.ANALYZE][l_idx % 3]
                activity = Activity(
                    title=f"Activity {a_idx+1}",
                    content_type=ContentType.VIDEO if a_idx == 0 else ContentType.READING,
                    bloom_level=bloom,
                    estimated_duration_minutes=5.0
                )
                lesson.activities.append(activity)
            module.lessons.append(lesson)
        course.modules.append(module)

    tmp_store.save(course)
    return course

@pytest.fixture
def invalid_course(tmp_store):
    """Create a course that fails validation."""
    course = Course(title="Invalid Course")
    # Only 1 module (needs 2-3)
    course.modules = [Module(title="Only One")]
    tmp_store.save(course)
    return course

class TestValidateEndpoint:
    def test_validate_returns_report(self, client, valid_course):
        response = client.get(f'/api/courses/{valid_course.id}/validate')
        assert response.status_code == 200

        data = response.get_json()
        assert "is_publishable" in data
        assert "validators" in data
        assert "summary" in data
        assert "CourseValidator" in data["validators"]
        assert "OutcomeValidator" in data["validators"]
        assert "BloomsValidator" in data["validators"]
        assert "DistractorValidator" in data["validators"]

    def test_validate_returns_errors_for_invalid(self, client, invalid_course):
        response = client.get(f'/api/courses/{invalid_course.id}/validate')
        assert response.status_code == 200

        data = response.get_json()
        assert data["is_publishable"] is False
        assert data["summary"]["total_errors"] > 0

    def test_validate_course_not_found(self, client):
        response = client.get('/api/courses/nonexistent/validate')
        assert response.status_code == 404

class TestPublishableEndpoint:
    def test_publishable_quick_check(self, client, valid_course):
        response = client.get(f'/api/courses/{valid_course.id}/publishable')
        assert response.status_code == 200

        data = response.get_json()
        assert "is_publishable" in data
        assert "error_count" in data

    def test_publishable_returns_false_for_invalid(self, client, invalid_course):
        response = client.get(f'/api/courses/{invalid_course.id}/publishable')
        assert response.status_code == 200

        data = response.get_json()
        assert data["is_publishable"] is False
        assert data["error_count"] > 0

class TestBuildStatePublishingGate:
    def test_publish_blocked_for_invalid_course(self, client, invalid_course, tmp_store):
        # Create an activity in APPROVED state
        lesson = Lesson(title="L1")
        activity = Activity(
            title="A1",
            build_state=BuildState.APPROVED,
            estimated_duration_minutes=60
        )
        lesson.activities.append(activity)
        invalid_course.modules[0].lessons.append(lesson)
        tmp_store.save(invalid_course)

        # Try to publish - should fail due to validation
        response = client.put(
            f'/api/courses/{invalid_course.id}/activities/{activity.id}/state',
            json={"build_state": "published"}
        )
        assert response.status_code == 400
        data = response.get_json()
        assert "validation" in data["error"].lower()
```
  </action>
  <verify>pytest tests/test_validation_api.py -v</verify>
  <done>All validation API tests pass</done>
</task>

</tasks>

<verification>
- ValidationReport.validate_course() returns dict of validator results
- ValidationReport.is_publishable() returns true only if no errors
- GET /api/courses/<id>/validate returns comprehensive report
- GET /api/courses/<id>/publishable returns quick check
- APPROVED -> PUBLISHED transition blocked if validation fails
- All tests pass: pytest tests/test_validation_api.py -v
- Full test suite passes: pytest
</verification>

<success_criteria>
- ValidationReport aggregates all 4 validators
- /api/courses/<id>/validate returns is_publishable, validators dict, summary counts
- /api/courses/<id>/publishable returns quick check result
- Build state transition to PUBLISHED checks validation
- Invalid courses cannot publish (400 error with message)
- Valid courses can publish normally
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-validation-quality/07-05-SUMMARY.md`
</output>
