---
phase: 07-validation-quality
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/validators/validation_result.py
  - src/validators/course_validator.py
  - tests/test_course_validator.py
autonomous: true

must_haves:
  truths:
    - "ValidationResult dataclass provides consistent structure for all validators"
    - "CourseValidator validates Course objects (not just blueprints)"
    - "Validation returns errors (blockers), warnings (non-blocking), and suggestions (optional)"
  artifacts:
    - path: "src/validators/validation_result.py"
      provides: "ValidationResult dataclass"
      exports: ["ValidationResult"]
    - path: "src/validators/course_validator.py"
      provides: "CourseValidator for Course objects"
      contains: "def validate_course"
  key_links:
    - from: "src/validators/course_validator.py"
      to: "src/validators/validation_result.py"
      via: "import"
      pattern: "from src.validators.validation_result import ValidationResult"
---

<objective>
Create the validation infrastructure with a shared ValidationResult dataclass and extend CourseValidator to validate Course objects (not just blueprints).

Purpose: Establishes the foundation for all Phase 7 validators. Currently CourseraValidator only validates CourseBlueprint objects. We need a CourseValidator that works with the Course dataclass from models.py, using the same validation rules.

Output: ValidationResult dataclass used by all validators, CourseValidator class that validates Course objects with the same Coursera requirements (duration, module count, content distribution).
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-validation-quality/07-RESEARCH.md
@src/validators/course_validator.py
@src/core/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ValidationResult dataclass</name>
  <files>src/validators/validation_result.py</files>
  <action>
Create a new file `src/validators/validation_result.py` with a ValidationResult dataclass:

```python
from dataclasses import dataclass, field
from typing import List, Dict, Any

@dataclass
class ValidationResult:
    """Validation result for any validation check.

    Three-tier structure:
    - errors: Blockers that prevent publishing
    - warnings: Non-blocking issues to address
    - suggestions: Optional improvements
    """
    is_valid: bool
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)
    metrics: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dictionary for API responses."""
        return {
            "is_valid": self.is_valid,
            "errors": self.errors,
            "warnings": self.warnings,
            "suggestions": self.suggestions,
            "metrics": self.metrics
        }
```

This replaces the existing BlueprintValidation class in course_validator.py with a more generic result type that all validators will use.
  </action>
  <verify>python -c "from src.validators.validation_result import ValidationResult; r = ValidationResult(is_valid=True); print(r.to_dict())"</verify>
  <done>ValidationResult is importable and to_dict() returns expected structure</done>
</task>

<task type="auto">
  <name>Task 2: Create CourseValidator for Course objects</name>
  <files>src/validators/course_validator.py</files>
  <action>
Add a new CourseValidator class to the existing course_validator.py file (keep CourseraValidator for backward compatibility with blueprint validation):

```python
from src.validators.validation_result import ValidationResult
from src.core.models import Course, Activity

class CourseValidator:
    """Validates Course objects against Coursera short course requirements.

    All validation is deterministic Python logic - never uses AI.
    """

    # Constants (same as CourseraValidator)
    MIN_DURATION = 30
    MAX_DURATION = 180
    MIN_MODULES = 2
    MAX_MODULES = 3
    MIN_LESSONS_PER_MODULE = 3
    MAX_LESSONS_PER_MODULE = 5
    MIN_ACTIVITIES_PER_LESSON = 2
    MAX_ACTIVITIES_PER_LESSON = 4
    TARGET_VIDEO_PCT = 0.30
    TARGET_READING_PCT = 0.20
    TARGET_PRACTICE_PCT = 0.30
    TARGET_ASSESSMENT_PCT = 0.20
    DISTRIBUTION_TOLERANCE = 0.15

    def validate(self, course: Course) -> ValidationResult:
        """Run all validation checks on a Course object."""
        errors = []
        warnings = []
        suggestions = []

        # Get all activities
        all_activities = self._flatten_activities(course)

        # ERROR: Module count (2-3)
        module_count = len(course.modules)
        if not (self.MIN_MODULES <= module_count <= self.MAX_MODULES):
            errors.append(
                f"Must have {self.MIN_MODULES}-{self.MAX_MODULES} modules, got {module_count}"
            )

        # ERROR: Total duration (30-180 min)
        total_duration = sum(a.estimated_duration_minutes for a in all_activities)
        if total_duration < self.MIN_DURATION:
            errors.append(f"Duration {total_duration:.0f}min below minimum {self.MIN_DURATION}min")
        elif total_duration > self.MAX_DURATION:
            errors.append(f"Duration {total_duration:.0f}min exceeds maximum {self.MAX_DURATION}min")

        # ERROR: Duration deviation from target (if specified)
        target = course.target_duration_minutes
        if target and total_duration > 0:
            deviation = abs(total_duration - target) / target
            if deviation > 0.20:
                errors.append(
                    f"Duration {total_duration:.0f}min deviates {deviation:.0%} from target {target}min (max 20%)"
                )

        # WARNING: Lessons per module (3-5)
        for i, module in enumerate(course.modules, 1):
            lesson_count = len(module.lessons)
            if lesson_count > 0 and not (self.MIN_LESSONS_PER_MODULE <= lesson_count <= self.MAX_LESSONS_PER_MODULE):
                warnings.append(
                    f"Module {i} has {lesson_count} lessons (recommended {self.MIN_LESSONS_PER_MODULE}-{self.MAX_LESSONS_PER_MODULE})"
                )

        # WARNING: Activities per lesson (2-4)
        for module in course.modules:
            for lesson in module.lessons:
                activity_count = len(lesson.activities)
                if activity_count > 0 and not (self.MIN_ACTIVITIES_PER_LESSON <= activity_count <= self.MAX_ACTIVITIES_PER_LESSON):
                    warnings.append(
                        f"Lesson '{lesson.title}' has {activity_count} activities (recommended {self.MIN_ACTIVITIES_PER_LESSON}-{self.MAX_ACTIVITIES_PER_LESSON})"
                    )

        # WARNING: Video content percentage
        total_activities = len(all_activities)
        if total_activities > 0:
            from collections import Counter
            type_counts = Counter(a.content_type.value for a in all_activities)
            video_pct = type_counts.get('video', 0) / total_activities
            if abs(video_pct - self.TARGET_VIDEO_PCT) > self.DISTRIBUTION_TOLERANCE:
                warnings.append(f"Video content {video_pct:.0%} (target ~{self.TARGET_VIDEO_PCT:.0%})")

        # WARNING: Bloom's diversity (3+ levels)
        bloom_levels = [a.bloom_level for a in all_activities if a.bloom_level]
        unique_blooms = len(set(bloom_levels))
        if bloom_levels and unique_blooms < 3:
            warnings.append(f"Only {unique_blooms} Bloom's taxonomy level(s) used (recommended 3+)")

        # SUGGESTION: No assessments
        has_quiz = any(a.content_type.value == 'quiz' for a in all_activities)
        if not has_quiz:
            suggestions.append("Consider adding quiz activities for knowledge assessment")

        # Build metrics
        content_distribution = {}
        if total_activities > 0:
            from collections import Counter
            type_counts = Counter(a.content_type.value for a in all_activities)
            content_distribution = {ct: count / total_activities for ct, count in type_counts.items()}

        total_lessons = sum(len(m.lessons) for m in course.modules)

        metrics = {
            "total_duration": total_duration,
            "module_count": module_count,
            "total_lessons": total_lessons,
            "total_activities": total_activities,
            "content_distribution": content_distribution,
            "bloom_diversity": unique_blooms if bloom_levels else 0,
            "activities_per_lesson_avg": round(total_activities / total_lessons, 2) if total_lessons > 0 else 0
        }

        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
            metrics=metrics
        )

    def _flatten_activities(self, course: Course) -> List[Activity]:
        """Extract all activities from course structure."""
        activities = []
        for module in course.modules:
            for lesson in module.lessons:
                activities.extend(lesson.activities)
        return activities
```

Keep the existing CourseraValidator class unchanged for backward compatibility with blueprint validation.
  </action>
  <verify>python -c "from src.validators.course_validator import CourseValidator; print('CourseValidator imported')"</verify>
  <done>CourseValidator class is importable and has validate() method</done>
</task>

<task type="auto">
  <name>Task 3: Add tests for CourseValidator</name>
  <files>tests/test_course_validator.py</files>
  <action>
Create tests for the new CourseValidator class:

```python
"""Tests for CourseValidator with Course objects."""
import pytest
from src.validators.course_validator import CourseValidator
from src.validators.validation_result import ValidationResult
from src.core.models import Course, Module, Lesson, Activity, ContentType, BloomLevel

@pytest.fixture
def validator():
    return CourseValidator()

@pytest.fixture
def minimal_valid_course():
    """Create a minimal course that passes validation."""
    course = Course(title="Test Course", target_duration_minutes=60)
    # 2 modules, 3 lessons each, 2 activities each = 12 activities
    for m_idx in range(2):
        module = Module(title=f"Module {m_idx+1}")
        for l_idx in range(3):
            lesson = Lesson(title=f"Lesson {l_idx+1}")
            for a_idx in range(2):
                # Mix content types and bloom levels
                content_type = ContentType.VIDEO if a_idx == 0 else ContentType.READING
                bloom = [BloomLevel.REMEMBER, BloomLevel.UNDERSTAND, BloomLevel.APPLY][l_idx % 3]
                activity = Activity(
                    title=f"Activity {a_idx+1}",
                    content_type=content_type,
                    bloom_level=bloom,
                    estimated_duration_minutes=5.0
                )
                lesson.activities.append(activity)
            module.lessons.append(lesson)
        course.modules.append(module)
    return course

class TestValidationResult:
    def test_to_dict(self):
        result = ValidationResult(
            is_valid=True,
            errors=[],
            warnings=["warning1"],
            suggestions=["suggestion1"],
            metrics={"count": 5}
        )
        d = result.to_dict()
        assert d["is_valid"] is True
        assert d["warnings"] == ["warning1"]
        assert d["metrics"]["count"] == 5

class TestCourseValidatorModuleCount:
    def test_valid_module_count(self, validator, minimal_valid_course):
        result = validator.validate(minimal_valid_course)
        assert "modules" not in str(result.errors).lower() or result.is_valid

    def test_too_few_modules(self, validator):
        course = Course(title="Test")
        course.modules = [Module(title="Only One")]
        result = validator.validate(course)
        assert not result.is_valid
        assert any("modules" in e.lower() for e in result.errors)

    def test_too_many_modules(self, validator):
        course = Course(title="Test")
        course.modules = [Module(title=f"M{i}") for i in range(5)]
        result = validator.validate(course)
        assert not result.is_valid
        assert any("modules" in e.lower() for e in result.errors)

class TestCourseValidatorDuration:
    def test_duration_below_minimum(self, validator):
        course = Course(title="Test", target_duration_minutes=60)
        course.modules = [Module(title="M1"), Module(title="M2")]
        # No activities = 0 duration
        result = validator.validate(course)
        assert any("duration" in e.lower() and "below" in e.lower() for e in result.errors)

    def test_duration_above_maximum(self, validator):
        course = Course(title="Test", target_duration_minutes=60)
        course.modules = [Module(title="M1"), Module(title="M2")]
        # Add many long activities
        lesson = Lesson(title="L1")
        for i in range(20):
            lesson.activities.append(Activity(
                title=f"A{i}",
                estimated_duration_minutes=15.0  # 20 * 15 = 300 min
            ))
        course.modules[0].lessons.append(lesson)
        result = validator.validate(course)
        assert any("duration" in e.lower() and "exceeds" in e.lower() for e in result.errors)

class TestCourseValidatorWarnings:
    def test_lessons_per_module_warning(self, validator):
        course = Course(title="Test")
        module = Module(title="M1")
        module.lessons = [Lesson(title="L1")]  # Only 1 lesson
        course.modules = [module, Module(title="M2")]
        result = validator.validate(course)
        assert any("lessons" in w.lower() for w in result.warnings)

    def test_activities_per_lesson_warning(self, validator):
        course = Course(title="Test")
        lesson = Lesson(title="L1")
        lesson.activities = [Activity(title="A1", estimated_duration_minutes=30)]  # Only 1 activity
        module = Module(title="M1")
        module.lessons = [lesson]
        course.modules = [module, Module(title="M2")]
        result = validator.validate(course)
        assert any("activities" in w.lower() for w in result.warnings)

class TestCourseValidatorMetrics:
    def test_metrics_include_counts(self, validator, minimal_valid_course):
        result = validator.validate(minimal_valid_course)
        assert "module_count" in result.metrics
        assert "total_lessons" in result.metrics
        assert "total_activities" in result.metrics
        assert result.metrics["module_count"] == 2
        assert result.metrics["total_lessons"] == 6
        assert result.metrics["total_activities"] == 12
```

Run the tests to verify everything works.
  </action>
  <verify>pytest tests/test_course_validator.py -v</verify>
  <done>All CourseValidator tests pass</done>
</task>

</tasks>

<verification>
- ValidationResult is importable from src.validators.validation_result
- CourseValidator is importable from src.validators.course_validator
- CourseValidator.validate() returns ValidationResult
- All tests pass: pytest tests/test_course_validator.py -v
- Existing CourseraValidator still works (backward compatibility)
</verification>

<success_criteria>
- ValidationResult dataclass exists with is_valid, errors, warnings, suggestions, metrics fields
- CourseValidator validates Course objects with same rules as CourseraValidator (module count, duration, distribution)
- Tests cover module count errors, duration errors, warnings, and metrics
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-validation-quality/07-01-SUMMARY.md`
</output>
