---
phase: 12-ai-interactive-features
plan: 09
type: execute
wave: 2
depends_on: [12-08]
files_modified:
  - src/coach/evaluator.py
  - src/coach/transcript.py
  - src/api/coach_bp.py
  - app.py
  - tests/test_coach_api.py
autonomous: true

must_haves:
  truths:
    - "System evaluates student responses against rubric"
    - "Session transcripts are saved for instructor review"
    - "Coach generates conversation summary with progress indicators"
    - "API supports streaming for real-time chat"
  artifacts:
    - path: "src/coach/evaluator.py"
      provides: "Rubric-based evaluation"
      exports: ["CoachEvaluator"]
    - path: "src/coach/transcript.py"
      provides: "Transcript storage and retrieval"
      exports: ["TranscriptStore"]
    - path: "src/api/coach_bp.py"
      provides: "Coach API endpoints"
      exports: ["init_coach_bp"]
  key_links:
    - from: "src/api/coach_bp.py"
      to: "ConversationManager"
      via: "session management"
      pattern: "manager\\.add_message"
    - from: "src/coach/evaluator.py"
      to: "rubric criteria"
      via: "level assessment"
      pattern: "developing|proficient|exemplary"
---

<objective>
Build the Coach evaluation engine, transcript storage, and API endpoints.

Purpose: Enable real-time evaluation of student responses, transcript saving for instructor review, and the API for interactive coaching (COACH-05, COACH-06, COACH-08). Completes the coach backend.
Output: CoachEvaluator for rubric scoring, TranscriptStore for persistence, and Coach API Blueprint.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/12-ai-interactive-features/12-RESEARCH.md

# Coach schema with evaluation criteria
@src/generators/schemas/coach.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CoachEvaluator and TranscriptStore</name>
  <files>
    src/coach/evaluator.py
    src/coach/transcript.py
    src/coach/__init__.py
  </files>
  <action>
1. Create `src/coach/evaluator.py`:
   - EvaluationResult dataclass:
     - level: str ("developing" | "proficient" | "exemplary")
     - score: int (1-3)
     - criteria_met: List[str]
     - criteria_missing: List[str]
     - feedback: str
     - strengths: List[str]
     - areas_for_improvement: List[str]

   - CoachEvaluator class:
     - __init__(evaluation_criteria: dict) - from CoachSchema
     - evaluate_response(student_response: str, context: dict) -> EvaluationResult
       - Use Claude to assess against 3-level rubric
       - Return level with evidence
     - evaluate_session(transcript: List[Message]) -> SessionEvaluation
       - Evaluate overall session performance
       - Track progress across conversation
     - generate_summary(transcript: List[Message], evaluation: SessionEvaluation) -> str
       - Generate natural language summary
       - Include learning progress indicators

   - SessionEvaluation dataclass:
     - overall_level: str
     - progress_trajectory: str ("improving" | "consistent" | "struggling")
     - key_insights: List[str]
     - recommendations: List[str]
     - time_spent: int (seconds)
     - turns_count: int

   - Use 3-level rubric from CoachSchema:
     - developing (1): Basic understanding, needs guidance
     - proficient (2): Solid understanding, applies concepts
     - exemplary (3): Deep understanding, extends concepts

2. Create `src/coach/transcript.py`:
   - Transcript dataclass:
     - id: str
     - session_id: str
     - activity_id: str
     - course_id: str
     - user_id: str
     - messages: List[Message]
     - started_at: str
     - ended_at: Optional[str]
     - evaluation: Optional[SessionEvaluation]
     - summary: Optional[str]

   - TranscriptStore class:
     - __init__(project_store: ProjectStore)
     - save_transcript(transcript: Transcript) -> str
     - get_transcript(course_id: str, transcript_id: str) -> Transcript
     - list_transcripts(course_id: str, activity_id: str = None, user_id: str = None) -> List[Transcript]
     - delete_transcript(course_id: str, transcript_id: str) -> bool
     - get_session_stats(course_id: str, activity_id: str) -> dict
       - Average session duration, completion rate, level distribution

   - Store transcripts in course_data.json under course.transcripts array

3. Update `src/coach/__init__.py` to export new classes
  </action>
  <verify>
    python -c "from src.coach import CoachEvaluator, TranscriptStore; print('Imports OK')"
  </verify>
  <done>
    CoachEvaluator and TranscriptStore handle evaluation and persistence
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Coach API Blueprint with streaming and tests</name>
  <files>
    src/api/coach_bp.py
    app.py
    tests/test_coach_api.py
  </files>
  <action>
1. Create `src/api/coach_bp.py`:
   - init_coach_bp(project_store) -> Blueprint

   POST /api/courses/<course_id>/activities/<activity_id>/coach/start
   - Starts new coaching session
   - Returns: {session_id, persona, dialogue_structure, welcome_message}
   - Creates ConversationManager for session

   POST /api/courses/<course_id>/activities/<activity_id>/coach/chat
   - Accepts: JSON with {session_id: str, message: str}
   - Returns: {response: str, evaluation?: EvaluationResult}
   - Non-streaming for simple chat

   POST /api/courses/<course_id>/activities/<activity_id>/coach/chat/stream
   - Accepts: JSON with {session_id: str, message: str}
   - Returns: SSE stream with coach response
   - Events: {type: 'chunk', text: str}, {type: 'evaluation', data: EvaluationResult}

   POST /api/courses/<course_id>/activities/<activity_id>/coach/end
   - Accepts: JSON with {session_id: str}
   - Evaluates full session, saves transcript
   - Returns: {transcript_id, evaluation, summary}

   GET /api/courses/<course_id>/activities/<activity_id>/coach/session/<session_id>
   - Returns current session state (messages, coverage, evaluation)

   POST /api/courses/<course_id>/activities/<activity_id>/coach/continue
   - Accepts: JSON with {transcript_id: str}
   - Loads previous session and continues
   - Returns: {session_id, messages, coverage}

   GET /api/courses/<course_id>/activities/<activity_id>/transcripts
   - List all transcripts for activity
   - Returns: {transcripts: List[Transcript]}

   GET /api/courses/<course_id>/transcripts/<transcript_id>
   - Get specific transcript
   - Returns: {transcript: Transcript}

2. Register blueprint in app.py

3. Create `tests/test_coach_api.py`:
   - Test session start with persona
   - Test chat message/response
   - Test SSE streaming format
   - Test session evaluation
   - Test transcript save and retrieve
   - Test session continuity
   - Test authentication required
   - Mock Claude API for all tests
  </action>
  <verify>
    pytest tests/test_coach_api.py -v
  </verify>
  <done>
    Coach API endpoints work with streaming and transcript storage
  </done>
</task>

</tasks>

<verification>
- CoachEvaluator returns 3-level rubric assessment
- SessionEvaluation includes progress trajectory
- Transcripts persist and are retrievable
- Streaming chat works with SSE
- Session continuity works (resume previous)
- All tests pass (target: 18+ tests)
</verification>

<success_criteria>
- POST /coach/start returns session with persona
- POST /coach/chat returns response with evaluation
- POST /coach/chat/stream returns SSE stream
- POST /coach/end saves transcript with evaluation
- Transcripts retrievable by instructor
- All tests pass with mocked AI
</success_criteria>

<output>
After completion, create `.planning/phases/12-ai-interactive-features/12-09-SUMMARY.md`
</output>
