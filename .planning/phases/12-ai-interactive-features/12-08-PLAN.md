---
phase: 12-ai-interactive-features
plan: 08
type: execute
wave: 1
depends_on: []
files_modified:
  - src/coach/__init__.py
  - src/coach/conversation.py
  - src/coach/guardrails.py
  - src/coach/persona.py
  - tests/test_coach_conversation.py
autonomous: true

must_haves:
  truths:
    - "Student can have a multi-turn conversation with the coach"
    - "Coach remembers earlier parts of the conversation"
    - "Coach guides student through required learning points"
    - "Coach responds in its configured personality style"
    - "Coach asks guiding questions when Socratic mode is enabled"
  artifacts:
    - path: "src/coach/conversation.py"
      provides: "Conversation management with token tracking"
      exports: ["ConversationManager"]
    - path: "src/coach/guardrails.py"
      provides: "Topic and structure enforcement"
      exports: ["GuardrailEngine"]
    - path: "src/coach/persona.py"
      provides: "Configurable coach personality"
      exports: ["CoachPersona"]
  key_links:
    - from: "src/coach/conversation.py"
      to: "Claude API"
      via: "streaming messages"
      pattern: "client\\.messages\\.stream"
    - from: "src/coach/guardrails.py"
      to: "CoachSchema"
      via: "structure validation"
      pattern: "dialogue_structure"
---

<objective>
Build the Interactive Coach conversation engine with guardrails and persona.

Purpose: Enable AI-guided conversations where students interact with an AI tutor that follows the generated dialogue structure (COACH-01, COACH-02, COACH-03, COACH-04, COACH-07). Core backend for interactive coaching.
Output: ConversationManager with token budget, GuardrailEngine for topic enforcement, CoachPersona for configurable personality.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/12-ai-interactive-features/12-RESEARCH.md

# Coach dialogue schema
@src/generators/schemas/coach.py
@src/generators/coach_generator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ConversationManager with token budget</name>
  <files>
    src/coach/__init__.py
    src/coach/conversation.py
  </files>
  <action>
1. Create `src/coach/__init__.py` - package init

2. Create `src/coach/conversation.py`:
   - Message dataclass:
     - role: str ("user" | "assistant" | "system")
     - content: str
     - timestamp: str
     - token_count: int

   - ConversationManager class per RESEARCH.md Pattern 3:
     - __init__(max_tokens: int = 8000, session_id: str = None)
     - add_message(role: str, content: str) -> None
       - Count tokens using simple word-based estimation (words * 1.3)
       - Check budget and compact if needed
     - get_context() -> List[dict]
       - Return messages in Claude API format
       - Include system prompt + summaries + recent messages
     - compact_history() -> None
       - Keep most recent 5 messages
       - Summarize older messages using Claude
       - Store summary in self.summaries
     - get_full_transcript() -> List[Message]
       - Return all messages including summarized ones
     - save_transcript() -> dict
       - Export full transcript for storage
     - load_transcript(data: dict) -> None
       - Restore from saved state

   - Token budget management:
     - Track cumulative tokens
     - Trigger compaction at 80% capacity (6400 tokens for 8000 limit)
     - Keep system prompt + learning outcomes + recent 5 messages
     - Store full transcript separately for instructor review

   - Session continuity:
     - save() and load() for resume capability
     - Include summaries in saved state
  </action>
  <verify>
    python -c "from src.coach import ConversationManager; print('Import OK')"
  </verify>
  <done>
    ConversationManager handles token budget with compaction
  </done>
</task>

<task type="auto">
  <name>Task 2: Create GuardrailEngine and CoachPersona with tests</name>
  <files>
    src/coach/guardrails.py
    src/coach/persona.py
    src/coach/__init__.py
    tests/test_coach_conversation.py
  </files>
  <action>
1. Create `src/coach/guardrails.py`:
   - GuardrailEngine class:
     - __init__(dialogue_structure: dict, learning_outcomes: List[str])
     - build_system_prompt(persona: CoachPersona) -> str
       - Include dialogue structure as guardrails
       - Include learning outcomes for topic bounds
       - Include persona characteristics
     - check_coverage(transcript: List[Message]) -> CoverageResult
       - Check which dialogue sections have been covered
       - Return list of remaining key points
     - is_on_topic(message: str) -> bool
       - Check if student message relates to learning outcomes
     - get_redirect_prompt(off_topic_message: str) -> str
       - Generate gentle redirect back to topic

   - CoverageResult dataclass:
     - covered_sections: List[str]
     - remaining_sections: List[str]
     - coverage_percent: float
     - key_points_addressed: List[str]

   - Dialogue section tracking based on CoachSchema structure:
     - context_setting, skill_introduction, guided_practice, etc.

2. Create `src/coach/persona.py`:
   - CoachPersona dataclass:
     - name: str (default "Coach")
     - personality: str ("supportive" | "challenging" | "formal" | "friendly")
     - style: str (communication style description)
     - socratic: bool (whether to use Socratic method)
     - off_topic_handling: str ("strict" | "moderate" | "flexible")
     - avatar: Optional[str] (avatar identifier)

   - PersonaBuilder class:
     - from_activity(activity: Activity) -> CoachPersona
       - Load persona from activity.metadata if configured
       - Use defaults if not configured
     - get_personality_prompt(persona: CoachPersona) -> str
       - Generate personality description for system prompt

   - Socratic method prompt:
     - When socratic=True: "Guide the learner through questions rather than giving direct answers"
     - Include probing question examples

3. Update `src/coach/__init__.py` to export all classes

4. Create `tests/test_coach_conversation.py`:
   - Test ConversationManager token tracking
   - Test history compaction
   - Test save/load session continuity
   - Test GuardrailEngine coverage tracking
   - Test on-topic detection
   - Test redirect prompts
   - Test CoachPersona generation
   - Test Socratic method prompts
  </action>
  <verify>
    pytest tests/test_coach_conversation.py -v
  </verify>
  <done>
    GuardrailEngine and CoachPersona work for topic enforcement and personality
  </done>
</task>

</tasks>

<verification>
- ConversationManager tracks tokens and compacts at 80% capacity
- GuardrailEngine tracks dialogue section coverage
- On-topic detection uses learning outcomes
- Persona affects system prompt tone
- Socratic method changes questioning style
- All tests pass (target: 15+ tests)
</verification>

<success_criteria>
- Token budget prevents context overflow
- Compaction summarizes old messages
- Coverage tracking shows progress through dialogue sections
- Persona customization works for all personality types
- Socratic mode uses questions instead of answers
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/12-ai-interactive-features/12-08-SUMMARY.md`
</output>
