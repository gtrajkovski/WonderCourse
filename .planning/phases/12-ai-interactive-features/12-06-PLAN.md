---
phase: 12-ai-interactive-features
plan: 06
type: execute
wave: 2
depends_on: [12-05]
files_modified:
  - src/editing/autocomplete.py
  - src/editing/bloom_analyzer.py
  - src/api/edit_bp.py
  - tests/test_editing_autocomplete.py
autonomous: true

must_haves:
  truths:
    - "User receives ghost text suggestions while typing"
    - "Autocomplete respects course context and outcomes"
    - "System detects Bloom's level of current content"
    - "Bloom's level warnings appear when misaligned"
  artifacts:
    - path: "src/editing/autocomplete.py"
      provides: "Context-aware autocomplete"
      exports: ["AutocompleteEngine"]
    - path: "src/editing/bloom_analyzer.py"
      provides: "Bloom's level detection"
      exports: ["BloomAnalyzer"]
  key_links:
    - from: "src/api/edit_bp.py"
      to: "AutocompleteEngine"
      via: "import and call"
      pattern: "engine\\.complete"
    - from: "src/editing/bloom_analyzer.py"
      to: "BloomLevel enum"
      via: "return type"
      pattern: "BloomLevel\\."
---

<objective>
Build context-aware autocomplete and Bloom's level analysis for inline editing.

Purpose: Enable ghost text suggestions based on course context and detect/warn about Bloom's level misalignment (EDIT-02, EDIT-04). These features make editing intelligent and aligned with learning outcomes.
Output: AutocompleteEngine with course context awareness and BloomAnalyzer for cognitive level detection.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/12-ai-interactive-features/12-RESEARCH.md

# Bloom's validation exists
@src/validators/blooms_validator.py
@src/core/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AutocompleteEngine and BloomAnalyzer</name>
  <files>
    src/editing/autocomplete.py
    src/editing/bloom_analyzer.py
    src/editing/__init__.py
  </files>
  <action>
1. Create `src/editing/autocomplete.py`:
   - AutocompleteEngine class with:
     - __init__(model: str = "claude-3-5-haiku-20241022") - Use Haiku for speed per RESEARCH.md
     - complete(text: str, context: dict, max_tokens: int = 50) -> CompletionResult
     - get_sentence_completion(text: str, context: dict) -> str

   - CompletionResult dataclass:
     - suggestion: str (the ghost text)
     - confidence: float
     - full_text: str (original + suggestion)

   - Context dict supports:
     - learning_outcomes: List[str]
     - activity_title: str
     - content_type: str
     - course_title: str
     - existing_content: str (preceding paragraphs for context)

   - System prompt includes:
     - "Complete this sentence in a way that aligns with the learning outcomes"
     - Include course context for relevance
     - Keep completion short (1-2 sentences max)

   - Use low max_tokens (50) for fast response per RESEARCH.md

2. Create `src/editing/bloom_analyzer.py`:
   - BloomAnalyzer class with:
     - analyze(text: str) -> BloomAnalysis
     - check_alignment(text: str, target_level: BloomLevel) -> AlignmentResult

   - BloomAnalysis dataclass:
     - detected_level: BloomLevel
     - confidence: float
     - evidence: List[str] (verbs/phrases that indicate level)
     - verb_counts: dict (count of verbs per level)

   - AlignmentResult dataclass:
     - aligned: bool
     - current_level: BloomLevel
     - target_level: BloomLevel
     - gap: int (levels difference, negative if below target)
     - suggestions: List[str] (how to adjust)

   - Detection logic (can be rule-based for speed):
     - REMEMBER: define, list, recall, identify, name
     - UNDERSTAND: explain, describe, summarize, interpret
     - APPLY: use, implement, solve, demonstrate
     - ANALYZE: compare, contrast, examine, differentiate
     - EVALUATE: assess, critique, judge, justify
     - CREATE: design, develop, construct, propose

   - check_alignment compares detected vs target and returns suggestions

3. Update `src/editing/__init__.py` to export new classes
  </action>
  <verify>
    python -c "from src.editing import AutocompleteEngine, BloomAnalyzer; print('Imports OK')"
  </verify>
  <done>
    AutocompleteEngine and BloomAnalyzer importable with context awareness
  </done>
</task>

<task type="auto">
  <name>Task 2: Add autocomplete and Bloom's endpoints with tests</name>
  <files>
    src/api/edit_bp.py
    tests/test_editing_autocomplete.py
  </files>
  <action>
1. Add to `src/api/edit_bp.py`:

   POST /api/edit/autocomplete
   - Accepts: JSON with {text: str, context?: dict}
   - Returns: {suggestion, confidence, full_text}
   - Fast response (< 500ms target)

   POST /api/edit/bloom/analyze
   - Accepts: JSON with {text: str}
   - Returns: {detected_level, confidence, evidence, verb_counts}

   POST /api/edit/bloom/check
   - Accepts: JSON with {text: str, target_level: str}
   - Returns: {aligned, current_level, target_level, gap, suggestions}

   GET /api/courses/<course_id>/activities/<activity_id>/bloom
   - Analyzes activity content against target Bloom level
   - Returns alignment status and suggestions

2. Create `tests/test_editing_autocomplete.py`:
   - Test autocomplete with context
   - Test autocomplete without context (still works)
   - Test Bloom analysis for each level
   - Test Bloom alignment checking
   - Test verb detection accuracy
   - Test activity Bloom endpoint
   - Mock Claude API for autocomplete tests
   - Bloom analyzer can use rule-based (no mock needed)
  </action>
  <verify>
    pytest tests/test_editing_autocomplete.py -v
  </verify>
  <done>
    Autocomplete and Bloom's analysis endpoints work with context awareness
  </done>
</task>

</tasks>

<verification>
- AutocompleteEngine uses Haiku for fast responses
- Context (outcomes, content type) affects suggestions
- BloomAnalyzer detects level from verb patterns
- Alignment check returns gap and suggestions
- All tests pass (target: 12+ tests)
</verification>

<success_criteria>
- POST /api/edit/autocomplete returns completion in < 500ms
- Bloom analysis correctly identifies cognitive level
- Alignment check warns when content below/above target
- Suggestions for level adjustment are actionable
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/12-ai-interactive-features/12-06-SUMMARY.md`
</output>
