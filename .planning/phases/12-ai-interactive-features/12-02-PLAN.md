---
phase: 12-ai-interactive-features
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/import/parsers/docx_parser.py
  - src/import/parsers/html_parser.py
  - src/import/parsers/scorm_parser.py
  - src/import/parsers/qti_parser.py
  - src/import/parsers/__init__.py
  - requirements.txt
  - tests/test_import_parsers_advanced.py
autonomous: true

must_haves:
  truths:
    - "System can parse DOCX documents into structured content"
    - "System can parse HTML into clean content"
    - "System can parse SCORM packages into course structure"
    - "System can parse QTI files into quiz questions"
  artifacts:
    - path: "src/import/parsers/docx_parser.py"
      provides: "DOCX parsing via python-docx and mammoth"
      exports: ["DOCXParser"]
    - path: "src/import/parsers/scorm_parser.py"
      provides: "SCORM package parsing via lxml"
      exports: ["SCORMParser"]
    - path: "src/import/parsers/qti_parser.py"
      provides: "QTI quiz parsing"
      exports: ["QTIParser"]
  key_links:
    - from: "src/import/parsers/docx_parser.py"
      to: "python-docx + mammoth"
      via: "library import"
      pattern: "from docx import Document"
    - from: "src/import/parsers/scorm_parser.py"
      to: "lxml"
      via: "library import"
      pattern: "from lxml import etree"
---

<objective>
Build advanced content import parsers for DOCX, HTML, SCORM, and QTI formats.

Purpose: Enable users to import existing course content from document formats, LMS packages, and quiz interchange files (IMPORT-07). These are complex formats requiring specialized libraries.
Output: Four advanced parsers handling document and package formats with full fidelity.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/12-ai-interactive-features/12-RESEARCH.md

# Research patterns
@.planning/phases/12-ai-interactive-features/12-RESEARCH.md (SCORM parsing pattern, python-docx pattern)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and create DOCX and HTML parsers</name>
  <files>
    requirements.txt
    src/import/parsers/docx_parser.py
    src/import/parsers/html_parser.py
    src/import/parsers/__init__.py
  </files>
  <action>
1. Add to requirements.txt (after existing entries):
   - mammoth>=1.9.0
   - lxml>=5.0.0
   - beautifulsoup4>=4.12.0
   - bleach>=6.0.0

2. Create `src/import/parsers/docx_parser.py`:
   - Use python-docx (already in deps) for structured extraction
   - Use mammoth for semantic HTML conversion
   - Extract: title, paragraphs with styles, tables, lists
   - Detect content type from structure (headings = reading, numbered lists = steps)
   - Handle styles: Heading 1 = h1, Normal = p, etc.
   - Include metadata: author, created_date from docx properties
   - can_parse: bytes that start with DOCX magic bytes (PK header) or .docx filename

3. Create `src/import/parsers/html_parser.py`:
   - Use BeautifulSoup4 for HTML parsing
   - Use bleach to sanitize and strip unsafe tags
   - Extract text content preserving structure (headers, paragraphs, lists)
   - Remove scripts, styles, comments
   - Allowed tags: p, h1-h6, ul, ol, li, strong, em, a, br, table, tr, td, th
   - can_parse: string containing HTML tags (< and >)

4. Update `__init__.py` to export DOCXParser, HTMLParser
  </action>
  <verify>
    python -c "from src.import.parsers import DOCXParser, HTMLParser; print('Imports OK')"
  </verify>
  <done>
    DOCXParser and HTMLParser importable and ready for use
  </done>
</task>

<task type="auto">
  <name>Task 2: Create SCORM and QTI parsers with tests</name>
  <files>
    src/import/parsers/scorm_parser.py
    src/import/parsers/qti_parser.py
    src/import/parsers/__init__.py
    tests/test_import_parsers_advanced.py
  </files>
  <action>
1. Create `src/import/parsers/scorm_parser.py`:
   - Parse SCORM packages from ZIP bytes
   - Search for imsmanifest.xml at any depth (not just root - handle wrapper folders)
   - Use lxml with SCORM namespaces:
     - imscp: http://www.imsglobal.org/xsd/imscp_v1p1
     - adlcp: http://www.adlnet.org/xsd/adlcp_v1p3
   - Extract: organizations (course structure), items (modules/lessons), resources (content files)
   - Build module/lesson hierarchy from item nesting
   - Extract HTML content from referenced resources
   - can_parse: ZIP with imsmanifest.xml file
   - Return content_type='blueprint' with full course structure

2. Create `src/import/parsers/qti_parser.py`:
   - Parse QTI 2.1 XML for quiz questions
   - Extract: assessmentItem elements (questions), choiceInteraction (MCQ options)
   - Map responseDeclaration to identify correct answers
   - Extract: question prompt, options, correct answer, feedback
   - Handle common QTI structures (assessmentTest with sections)
   - can_parse: XML with QTI namespace or assessment elements
   - Return content_type='quiz' with questions list

3. Update `__init__.py` to export SCORMParser, QTIParser

4. Create `tests/test_import_parsers_advanced.py`:
   - Test DOCX parsing with sample .docx bytes
   - Test HTML parsing and sanitization
   - Test SCORM parsing with mock ZIP containing imsmanifest.xml
   - Test QTI parsing with sample XML
   - Test format detection for all parsers
   - Test error handling for malformed inputs
  </action>
  <verify>
    pytest tests/test_import_parsers_advanced.py -v
  </verify>
  <done>
    SCORM and QTI parsers pass tests for package parsing and quiz extraction
  </done>
</task>

</tasks>

<verification>
- All 4 advanced parsers importable
- DOCX parser extracts document structure and content
- HTML parser sanitizes and extracts clean content
- SCORM parser finds manifest anywhere in ZIP and extracts course structure
- QTI parser extracts quiz questions with options and correct answers
- All tests pass (target: 20+ tests)
</verification>

<success_criteria>
- dependencies added to requirements.txt
- DOCXParser handles python-docx extraction + mammoth HTML conversion
- HTMLParser sanitizes with bleach and extracts with BeautifulSoup
- SCORMParser handles non-root manifest locations per RESEARCH.md pitfall
- QTIParser extracts questions, options, and feedback
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/12-ai-interactive-features/12-02-SUMMARY.md`
</output>
