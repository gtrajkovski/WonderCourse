---
phase: 05-extended-content-generation
plan: 02
type: tdd
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/generators/hol_generator.py
  - tests/test_hol_generator.py
autonomous: true

must_haves:
  truths:
    - "HOLGenerator extends BaseGenerator[HOLSchema] and generates valid HOL activities"
    - "Generated HOL has scenario, exactly 3 parts, submission criteria, and 3-criterion rubric"
    - "HOL rubric uses Advanced/Intermediate/Beginner scoring at 5/4/2 points"
    - "Metadata includes word_count, estimated_duration_minutes, total_points, content_type"
  artifacts:
    - path: "src/generators/hol_generator.py"
      provides: "HOLGenerator class"
      contains: "class HOLGenerator"
    - path: "tests/test_hol_generator.py"
      provides: "Tests for HOLGenerator"
      contains: "test_generate_returns_valid_schema"
  key_links:
    - from: "src/generators/hol_generator.py"
      to: "src/generators/base_generator.py"
      via: "class inheritance"
      pattern: "class HOLGenerator\\(BaseGenerator\\[HOLSchema\\]\\)"
---

<objective>
Create HOLGenerator with TDD for Hands-on Lab activities with scenario-based structure and Advanced/Intermediate/Beginner rubric.

Purpose: Enable generation of HOL activities -- the most complex extended content type with unique 5/4/2 scoring.
Output: Working HOLGenerator with tests
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@src/generators/base_generator.py
@src/generators/quiz_generator.py
@tests/test_quiz_generator.py
@src/generators/schemas/hol.py
</context>

<feature>
  <name>HOLGenerator</name>
  <files>src/generators/hol_generator.py, tests/test_hol_generator.py</files>
  <behavior>
    HOLGenerator extends BaseGenerator[HOLSchema].

    - system_prompt: Expert instructional designer for hands-on labs. Guidelines for scenario-based learning, 3-part structure, submission criteria, and Advanced/Intermediate/Beginner rubric (5/4/2 points, total 15).
    - build_user_prompt(learning_objective, topic, difficulty="intermediate"): Returns formatted prompt requesting HOL with scenario, 3 parts, submission criteria, and 3-criterion rubric.
    - extract_metadata(content: HOLSchema) -> dict: Returns word_count (sum all text fields), estimated_duration_minutes (sum of part.estimated_minutes), total_points (15 for 3 criteria x 5 max), content_type ("hol").
    - generate_hol() convenience method wrapping generate(schema=HOLSchema, ...).

    Test cases:
    1. test_generate_returns_valid_schema - Mock API, verify HOLSchema instance with 3 parts and 3 rubric criteria
    2. test_rubric_uses_correct_scoring - Verify Advanced/Intermediate/Beginner (5/4/2), NOT Below/Meets/Exceeds
    3. test_system_prompt_mentions_scoring - System prompt references Advanced/Intermediate/Beginner and 5/4/2 points
    4. test_build_user_prompt_includes_params - Prompt includes learning_objective, topic, difficulty
    5. test_extract_metadata_calculates_duration - Duration is sum of part.estimated_minutes
    6. test_api_called_with_output_config - Verify output_config parameter used (not response_format)
  </behavior>
  <implementation>
    Follow quiz_generator.py pattern exactly. Create sample HOL JSON fixture with 3 parts and 3 rubric criteria. Mock Anthropic via `mocker.patch('src.generators.base_generator.Anthropic', return_value=mock_client)`.
  </implementation>
</feature>

<verification>
`pytest tests/test_hol_generator.py -v` -- all 6 tests pass
</verification>

<success_criteria>
- HOLGenerator importable and extends BaseGenerator[HOLSchema]
- All 6 tests pass with mocked API
- Rubric uses Advanced/Intermediate/Beginner scoring model
</success_criteria>

<output>
After completion, create `.planning/phases/05-extended-content-generation/05-02-SUMMARY.md`
</output>
