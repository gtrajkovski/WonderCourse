---
phase: 05-extended-content-generation
plan: 05
type: tdd
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/generators/lab_generator.py
  - tests/test_lab_generator.py
autonomous: true

must_haves:
  truths:
    - "LabGenerator extends BaseGenerator[LabSchema] and generates ungraded lab specifications"
    - "Generated lab has setup instructions with numbered steps and expected results"
    - "Lab is ungraded -- no points or rubric"
    - "Metadata includes word_count, estimated_duration_minutes, content_type"
  artifacts:
    - path: "src/generators/lab_generator.py"
      provides: "LabGenerator class"
      contains: "class LabGenerator"
    - path: "tests/test_lab_generator.py"
      provides: "Tests for LabGenerator"
      contains: "test_generate_returns_valid_schema"
  key_links:
    - from: "src/generators/lab_generator.py"
      to: "src/generators/base_generator.py"
      via: "class inheritance"
      pattern: "class LabGenerator\\(BaseGenerator\\[LabSchema\\]\\)"
---

<objective>
Create LabGenerator with TDD for ungraded programming lab activities with setup instructions and exercises.

Purpose: Enable generation of practice lab specifications that guide students through hands-on skill building.
Output: Working LabGenerator with tests
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@src/generators/base_generator.py
@src/generators/quiz_generator.py
@tests/test_quiz_generator.py
@src/generators/schemas/lab.py
</context>

<feature>
  <name>LabGenerator</name>
  <files>src/generators/lab_generator.py, tests/test_lab_generator.py</files>
  <behavior>
    LabGenerator extends BaseGenerator[LabSchema].

    - system_prompt: Expert lab designer for technical education. Guidelines: clear setup with verifiable steps, progressive exercises from simple to complex, focus on exploration not assessment, include prerequisites for environment readiness. Labs are ungraded practice activities.
    - build_user_prompt(learning_objective, topic, difficulty="intermediate", estimated_minutes=45): Returns formatted prompt for lab with setup instructions, exercises, and time estimate.
    - extract_metadata(content: LabSchema) -> dict: Returns word_count (sum all text fields), estimated_duration_minutes (content.estimated_minutes), num_exercises (len(lab_exercises)), num_setup_steps (len(setup_instructions)), content_type ("lab").
    - generate_lab() convenience method.

    Test cases:
    1. test_generate_returns_valid_schema - Mock API, verify LabSchema with setup_instructions and lab_exercises
    2. test_setup_steps_are_numbered - Each SetupStep has sequential step_number
    3. test_system_prompt_mentions_ungraded - System prompt says ungraded/practice
    4. test_build_user_prompt_includes_params - Prompt includes learning_objective, topic, estimated_minutes
    5. test_extract_metadata_uses_lab_duration - Duration comes from content.estimated_minutes, not word count
    6. test_api_called_with_output_config - Verify output_config parameter
  </behavior>
  <implementation>
    Follow quiz_generator.py pattern. Create sample lab JSON fixture with 3+ setup steps and 3+ exercises. Mock Anthropic via mocker.patch.
  </implementation>
</feature>

<verification>
`pytest tests/test_lab_generator.py -v` -- all 6 tests pass
</verification>

<success_criteria>
- LabGenerator importable and extends BaseGenerator[LabSchema]
- All 6 tests pass with mocked API
- Lab is clearly ungraded (no points/rubric)
</success_criteria>

<output>
After completion, create `.planning/phases/05-extended-content-generation/05-05-SUMMARY.md`
</output>
