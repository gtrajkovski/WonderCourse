---
phase: 05-extended-content-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/generators/schemas/hol.py
  - src/generators/schemas/coach.py
  - src/generators/schemas/practice_quiz.py
  - src/generators/schemas/lab.py
  - src/generators/schemas/discussion.py
  - src/generators/schemas/assignment.py
  - src/generators/schemas/project.py
  - src/generators/schemas/__init__.py
autonomous: true

must_haves:
  truths:
    - "All 7 new schema files exist and are importable"
    - "HOL schema uses Advanced/Intermediate/Beginner scoring (5/4/2 points), NOT Below/Meets/Exceeds"
    - "Coach schema has exactly 8 sections (learning_objectives, scenario, tasks, conversation_starters, sample_responses, evaluation_criteria, wrap_up, reflection_prompts)"
    - "PracticeQuizSchema is separate from QuizSchema even though structure is similar"
    - "All schemas produce valid JSON schemas via model_json_schema()"
  artifacts:
    - path: "src/generators/schemas/hol.py"
      provides: "HOLSchema with HOLPart, HOLRubricCriterion"
      contains: "class HOLSchema"
    - path: "src/generators/schemas/coach.py"
      provides: "CoachSchema with ConversationStarter, SampleResponse"
      contains: "class CoachSchema"
    - path: "src/generators/schemas/practice_quiz.py"
      provides: "PracticeQuizSchema separate from QuizSchema"
      contains: "class PracticeQuizSchema"
    - path: "src/generators/schemas/lab.py"
      provides: "LabSchema with SetupStep"
      contains: "class LabSchema"
    - path: "src/generators/schemas/discussion.py"
      provides: "DiscussionSchema with facilitation questions"
      contains: "class DiscussionSchema"
    - path: "src/generators/schemas/assignment.py"
      provides: "AssignmentSchema with deliverables and checklist"
      contains: "class AssignmentSchema"
    - path: "src/generators/schemas/project.py"
      provides: "ProjectMilestoneSchema with A1/A2/A3 staging"
      contains: "class ProjectMilestoneSchema"
  key_links:
    - from: "src/generators/schemas/__init__.py"
      to: "all 7 new schema modules"
      via: "import statements"
      pattern: "from src.generators.schemas.(hol|coach|practice_quiz|lab|discussion|assignment|project) import"
---

<objective>
Create 7 Pydantic v2 schemas for the extended content types: HOL, Coach Dialogue, Practice Quiz, Lab, Discussion, Assignment, and Project Milestone.

Purpose: These schemas define the structured output format for Claude API and enable type-safe validation for all Phase 5 generators.
Output: 7 schema files + updated __init__.py exports
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-extended-content-generation/05-RESEARCH.md
@src/generators/schemas/quiz.py
@src/generators/schemas/rubric.py
@src/generators/schemas/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create all 7 Pydantic schemas</name>
  <files>
    src/generators/schemas/hol.py
    src/generators/schemas/coach.py
    src/generators/schemas/practice_quiz.py
    src/generators/schemas/lab.py
    src/generators/schemas/discussion.py
    src/generators/schemas/assignment.py
    src/generators/schemas/project.py
  </files>
  <action>
Create 7 new schema files following the exact pattern from `src/generators/schemas/quiz.py` and `src/generators/schemas/rubric.py`. All use `from pydantic import BaseModel, Field` with `from typing import List, Literal`.

**1. `hol.py` - HOLSchema:**
- `HOLPart(BaseModel)`: part_number (int, ge=1), title (str), instructions (str), estimated_minutes (int, ge=1)
- `HOLRubricCriterion(BaseModel)`: name (str), advanced (str, description="Advanced performance (5 points)"), intermediate (str, description="Intermediate performance (4 points)"), beginner (str, description="Beginner performance (2 points)"), points_advanced (int, default=5), points_intermediate (int, default=4), points_beginner (int, default=2)
- `HOLSchema(BaseModel)`: title (str), scenario (str), parts (List[HOLPart], min_length=3, max_length=3), submission_criteria (str), rubric (List[HOLRubricCriterion], min_length=3, max_length=3), learning_objective (str)
- CRITICAL: Do NOT use Below/Meets/Exceeds. Use Advanced/Intermediate/Beginner with 5/4/2 points.

**2. `coach.py` - CoachSchema:**
- `ConversationStarter(BaseModel)`: starter_text (str), purpose (str)
- `SampleResponse(BaseModel)`: response_text (str), evaluation_level (Literal["exceeds", "meets", "needs_improvement"]), feedback (str)
- `CoachSchema(BaseModel)` with ALL 8 sections:
  1. title (str)
  2. learning_objectives (List[str], min_length=2, max_length=4)
  3. scenario (str)
  4. tasks (List[str], min_length=2, max_length=5)
  5. conversation_starters (List[ConversationStarter], min_length=3, max_length=5)
  6. sample_responses (List[SampleResponse], min_length=3, max_length=3)
  7. evaluation_criteria (List[str], min_length=3, max_length=5)
  8. wrap_up (str)
  9. reflection_prompts (List[str], min_length=2, max_length=4)

**3. `practice_quiz.py` - PracticeQuizSchema:**
- `PracticeQuizOption(BaseModel)`: text (str), is_correct (bool), feedback (str), hint (str, description="Hint to guide student toward correct answer")
- `PracticeQuizQuestion(BaseModel)`: question_text (str), options (List[PracticeQuizOption], min_length=3, max_length=4), bloom_level (Literal["remember","understand","apply","analyze","evaluate","create"]), explanation (str)
- `PracticeQuizSchema(BaseModel)`: title (str), questions (List[PracticeQuizQuestion], min_length=3, max_length=10), learning_objective (str)
- NOTE: Separate from QuizSchema. Adds `hint` field to options for formative feedback. No passing_score_percentage (formative, not graded).

**4. `lab.py` - LabSchema:**
- `SetupStep(BaseModel)`: step_number (int, ge=1), instruction (str), expected_result (str)
- `LabSchema(BaseModel)`: title (str), overview (str), learning_objectives (List[str], min_length=2, max_length=4), setup_instructions (List[SetupStep], min_length=3, max_length=10), lab_exercises (List[str], min_length=3, max_length=8), estimated_minutes (int, ge=15, le=120), prerequisites (List[str], min_length=0, max_length=3)

**5. `discussion.py` - DiscussionSchema:**
- `DiscussionSchema(BaseModel)`: title (str), main_prompt (str), facilitation_questions (List[str], min_length=3, max_length=5), engagement_hooks (List[str], min_length=2, max_length=3), connection_to_objective (str), learning_objective (str)

**6. `assignment.py` - AssignmentSchema:**
- `AssignmentDeliverable(BaseModel)`: item (str), points (int, ge=0)
- `ChecklistItem(BaseModel)`: item (str), required (bool)
- `AssignmentSchema(BaseModel)`: title (str), overview (str), deliverables (List[AssignmentDeliverable], min_length=1, max_length=5), grading_criteria (List[str], min_length=3, max_length=6), submission_checklist (List[ChecklistItem], min_length=3, max_length=10), total_points (int, gt=0), estimated_hours (int, ge=1, le=20), learning_objective (str)

**7. `project.py` - ProjectMilestoneSchema:**
- `MilestoneDeliverable(BaseModel)`: name (str), description (str), format (str)
- `ProjectMilestoneSchema(BaseModel)`: title (str), milestone_type (Literal["A1","A2","A3"]), overview (str), prerequisites (List[str], min_length=0, max_length=3), deliverables (List[MilestoneDeliverable], min_length=2, max_length=5), grading_criteria (List[str], min_length=3, max_length=6), estimated_hours (int, ge=1, le=40), learning_objective (str)

Each file must have a module docstring and class docstrings matching the style in quiz.py and rubric.py.
  </action>
  <verify>
Run in Python:
```python
python -c "
from src.generators.schemas.hol import HOLSchema, HOLPart, HOLRubricCriterion
from src.generators.schemas.coach import CoachSchema, ConversationStarter, SampleResponse
from src.generators.schemas.practice_quiz import PracticeQuizSchema, PracticeQuizQuestion, PracticeQuizOption
from src.generators.schemas.lab import LabSchema, SetupStep
from src.generators.schemas.discussion import DiscussionSchema
from src.generators.schemas.assignment import AssignmentSchema, AssignmentDeliverable, ChecklistItem
from src.generators.schemas.project import ProjectMilestoneSchema, MilestoneDeliverable
# Verify all produce valid JSON schemas
for schema in [HOLSchema, CoachSchema, PracticeQuizSchema, LabSchema, DiscussionSchema, AssignmentSchema, ProjectMilestoneSchema]:
    js = schema.model_json_schema()
    assert 'properties' in js, f'{schema.__name__} missing properties'
    print(f'{schema.__name__}: OK ({len(js[\"properties\"])} properties)')
# Verify HOL uses correct scoring
assert hasattr(HOLRubricCriterion, 'model_fields')
fields = HOLRubricCriterion.model_fields
assert 'advanced' in fields and 'beginner' in fields, 'HOL rubric must use Advanced/Beginner'
assert 'below_expectations' not in fields, 'HOL must NOT use Below/Meets/Exceeds'
print('All 7 schemas valid')
"
```
  </verify>
  <done>All 7 schema files importable with correct structure. HOL uses Advanced/Intermediate/Beginner (5/4/2). PracticeQuiz is separate from Quiz. Coach has 8 sections. All produce valid JSON schemas.</done>
</task>

<task type="auto">
  <name>Task 2: Update schemas __init__.py with all new exports</name>
  <files>src/generators/schemas/__init__.py</files>
  <action>
Update `src/generators/schemas/__init__.py` to import and export all new schema classes. Add imports for all 7 new schema modules and add their classes to `__all__`. Update the module docstring to reflect 11 content types (4 existing + 7 new).

Add these imports after existing ones:
```python
from src.generators.schemas.hol import HOLSchema, HOLPart, HOLRubricCriterion
from src.generators.schemas.coach import CoachSchema, ConversationStarter, SampleResponse
from src.generators.schemas.practice_quiz import PracticeQuizSchema, PracticeQuizQuestion, PracticeQuizOption
from src.generators.schemas.lab import LabSchema, SetupStep
from src.generators.schemas.discussion import DiscussionSchema
from src.generators.schemas.assignment import AssignmentSchema, AssignmentDeliverable, ChecklistItem
from src.generators.schemas.project import ProjectMilestoneSchema, MilestoneDeliverable
```

Add to `__all__`:
```python
# HOL
"HOLSchema", "HOLPart", "HOLRubricCriterion",
# Coach
"CoachSchema", "ConversationStarter", "SampleResponse",
# Practice Quiz
"PracticeQuizSchema", "PracticeQuizQuestion", "PracticeQuizOption",
# Lab
"LabSchema", "SetupStep",
# Discussion
"DiscussionSchema",
# Assignment
"AssignmentSchema", "AssignmentDeliverable", "ChecklistItem",
# Project
"ProjectMilestoneSchema", "MilestoneDeliverable",
```
  </action>
  <verify>
```bash
python -c "from src.generators.schemas import HOLSchema, CoachSchema, PracticeQuizSchema, LabSchema, DiscussionSchema, AssignmentSchema, ProjectMilestoneSchema; print('All schemas importable from package')"
```
  </verify>
  <done>All 7 new schemas importable from `src.generators.schemas` package. __init__.py updated with all exports.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.generators.schemas import *; print('Package import OK')"` succeeds
2. All 7 schema files exist in `src/generators/schemas/`
3. Each schema produces valid JSON schema via `model_json_schema()`
4. HOL rubric uses Advanced/Intermediate/Beginner fields (NOT Below/Meets/Exceeds)
5. PracticeQuizSchema is distinct from QuizSchema
6. Coach schema has all 8 sections
7. Existing tests still pass: `pytest tests/ -x -q`
</verification>

<success_criteria>
- 7 new schema files created and importable
- schemas/__init__.py updated with all new exports
- All existing tests pass (no regressions)
- HOL rubric correctly uses 5/4/2 scoring model
</success_criteria>

<output>
After completion, create `.planning/phases/05-extended-content-generation/05-01-SUMMARY.md`
</output>
