---
phase: 13-integration-polish
plan: 04
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - tests/e2e/conftest.py
  - tests/e2e/test_happy_path.py
  - tests/e2e/fixtures/mock_responses.py
  - pytest.ini
  - requirements.txt
autonomous: true

must_haves:
  truths:
    - "E2E tests run with Playwright against live Flask server"
    - "AI responses are mocked by default for fast, deterministic tests"
    - "Tests can optionally use real AI with --real-ai flag"
    - "Happy path workflow completes without errors"
  artifacts:
    - path: "tests/e2e/conftest.py"
      provides: "Playwright fixtures with live server"
      exports: ["live_server", "page", "mock_ai_responses"]
    - path: "tests/e2e/test_happy_path.py"
      provides: "Full workflow E2E test"
      contains: "test_registration_to_export"
    - path: "tests/e2e/fixtures/mock_responses.py"
      provides: "Mock AI response data"
      exports: ["MOCK_BLUEPRINT", "MOCK_VIDEO_SCRIPT"]
  key_links:
    - from: "tests/e2e/conftest.py"
      to: "app.py"
      via: "Flask server startup"
      pattern: "make_server"
---

<objective>
Set up E2E testing infrastructure with Playwright and create happy path test covering the full user workflow.

Purpose: Verify that all features work together in a real browser environment, catching integration issues that unit tests miss.
Output: Playwright test suite with mock AI responses and one comprehensive happy path test.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-integration-polish/13-CONTEXT.md
@.planning/phases/13-integration-polish/13-RESEARCH.md
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Set up Playwright infrastructure</name>
  <files>requirements.txt, pytest.ini, tests/e2e/__init__.py, tests/e2e/conftest.py</files>
  <action>
Update requirements.txt with:
- playwright>=1.42.0
- pytest-playwright>=0.4.0

Update pytest.ini to add custom option:
```ini
[pytest]
addopts = --strict-markers
markers =
    e2e: end-to-end browser tests
    slow: tests that take longer to run

# Custom option for real AI calls
# Usage: pytest tests/e2e --real-ai
```

Create tests/e2e/__init__.py (empty).

Create tests/e2e/conftest.py with fixtures:

1. pytest_addoption(parser) - add --real-ai flag

2. @pytest.fixture(scope="session") app():
   - Import create test app with isolated database
   - Configure TESTING=True

3. @pytest.fixture(scope="session") live_server(app):
   - Start Flask app in background thread using werkzeug.serving.make_server
   - Yield "http://localhost:5003"
   - Shutdown server on teardown

4. @pytest.fixture(scope="session") browser():
   - Launch chromium with sync_playwright
   - headless=True for CI, can override with HEADED=1 env var
   - Yield browser, close on teardown

5. @pytest.fixture page(browser, live_server):
   - Create new browser context and page
   - Set base URL to live_server
   - Yield page, close context on teardown

6. @pytest.fixture mock_ai_responses(page, request):
   - If --real-ai flag not set, route all /api/*/generate calls to mock handler
   - Return canned responses from fixtures/mock_responses.py
   - Yield, no cleanup needed

7. @pytest.fixture clean_db(app):
   - Reset database before each E2E test
   - Truncate users, courses tables
   - Re-seed permissions
  </action>
  <verify>pytest tests/e2e --collect-only shows fixtures available</verify>
  <done>Playwright fixtures configured, live server starts in background thread</done>
</task>

<task type="auto">
  <name>Task 2: Create mock AI response fixtures</name>
  <files>tests/e2e/fixtures/__init__.py, tests/e2e/fixtures/mock_responses.py</files>
  <action>
Create tests/e2e/fixtures/__init__.py (empty).

Create tests/e2e/fixtures/mock_responses.py with realistic mock data:

1. MOCK_BLUEPRINT - complete course blueprint with 2 modules, 3 lessons each:
   ```python
   MOCK_BLUEPRINT = {
       "title": "Introduction to Python",
       "description": "...",
       "modules": [
           {
               "title": "Getting Started",
               "lessons": [
                   {"title": "Installation", "activities": [...]},
                   ...
               ]
           },
           ...
       ]
   }
   ```

2. MOCK_VIDEO_SCRIPT - complete video script with WWHAA sections:
   ```python
   MOCK_VIDEO_SCRIPT = {
       "hook": "Have you ever wondered how...",
       "objective": "By the end of this video...",
       "content": "Let's start by...",
       "ivq": "Which of the following...",
       "summary": "Today we learned...",
       "cta": "In the next lesson..."
   }
   ```

3. MOCK_READING - reading with sections and references

4. MOCK_QUIZ - quiz with 3 questions and distractors

5. route_handler(route) function:
   - Match URL patterns to return appropriate mock
   - /blueprint/generate -> MOCK_BLUEPRINT
   - /generate with content_type=VIDEO -> MOCK_VIDEO_SCRIPT
   - etc.
  </action>
  <verify>python -c "from tests.e2e.fixtures.mock_responses import MOCK_BLUEPRINT; print(MOCK_BLUEPRINT['title'])"</verify>
  <done>Mock responses available for all content types</done>
</task>

<task type="auto">
  <name>Task 3: Create happy path E2E test</name>
  <files>tests/e2e/test_happy_path.py</files>
  <action>
Create tests/e2e/test_happy_path.py:

```python
import pytest
from playwright.sync_api import Page, expect

@pytest.mark.e2e
def test_registration_to_export(page: Page, mock_ai_responses, clean_db, live_server):
    """
    Full happy path: Register -> Create Course -> Generate Blueprint ->
    Generate Content -> Validate -> Export
    """
    # 1. Registration
    page.goto(f"{live_server}/register")
    page.fill('input[name="email"]', "e2e@test.com")
    page.fill('input[name="password"]', "testpassword123")
    page.fill('input[name="name"]', "E2E Test User")
    page.click('button[type="submit"]')

    # Should redirect to login with success message
    expect(page).to_have_url(f"{live_server}/login?registered=true")

    # 2. Login
    page.fill('input[name="email"]', "e2e@test.com")
    page.fill('input[name="password"]', "testpassword123")
    page.click('button[type="submit"]')

    # Should redirect to dashboard
    expect(page).to_have_url(f"{live_server}/dashboard")

    # 3. Create Course
    page.click('#create-course-btn')
    page.wait_for_selector('.modal')
    page.fill('input[name="title"]', "E2E Test Course")
    page.fill('textarea[name="description"]', "Test description")
    page.click('.modal button[type="submit"]')

    # Should see course in list
    page.wait_for_selector('.course-card:has-text("E2E Test Course")')

    # 4. Navigate to Planner, Generate Blueprint
    page.click('.course-card:has-text("E2E Test Course")')
    page.click('a[href*="planner"]')

    page.click('#blueprint-tab')
    page.click('#generate-blueprint-btn')
    page.wait_for_selector('.blueprint-preview', timeout=30000)

    # Accept blueprint
    page.click('#accept-blueprint-btn')

    # 5. Navigate to Studio, Generate Content
    page.click('a[href*="studio"]')
    page.wait_for_selector('.activity-list')
    page.click('.activity-item:first-child')
    page.click('#generate-btn')
    page.wait_for_selector('.content-preview:has-text("Hook")', timeout=30000)

    # 6. Navigate to Publish, Validate
    page.click('a[href*="publish"]')
    page.wait_for_selector('.validation-results')

    # 7. Export (may have warnings but should not error)
    page.click('#export-instructor-btn')
    # Wait for download or success message
    page.wait_for_selector('.toast-success', timeout=30000)
```

Add additional edge case tests:
- test_login_with_wrong_password - shows error, no redirect
- test_create_course_empty_title - shows validation error
  </action>
  <verify>pytest tests/e2e/test_happy_path.py -v -s --headed (run with browser visible)</verify>
  <done>Happy path test runs and passes with mocked AI, covers full workflow</done>
</task>

</tasks>

<verification>
- pytest tests/e2e --collect-only shows test discovered
- pytest tests/e2e/test_happy_path.py -v passes with mocks
- Test completes in under 60 seconds with mocks
- With HEADED=1, can see browser actions
- No flaky failures on repeated runs
</verification>

<success_criteria>
- Playwright installed and browser downloads work
- Live server fixture starts Flask in background
- AI responses mocked by default
- Happy path test covers registration through export
- Tests are deterministic (no flakiness)
</success_criteria>

<output>
After completion, create `.planning/phases/13-integration-polish/13-04-SUMMARY.md`
</output>
