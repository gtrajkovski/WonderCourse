---
phase: 13-integration-polish
plan: 07
type: execute
wave: 3
depends_on: ["13-04", "13-05", "13-06"]
files_modified:
  - tests/e2e/test_collaboration.py
  - tests/e2e/test_import_flows.py
  - tests/e2e/test_error_recovery.py
  - tests/e2e/test_coach.py
autonomous: true

must_haves:
  truths:
    - "Collaboration workflows work in E2E tests"
    - "Import flows complete successfully"
    - "Error recovery mechanisms work correctly"
    - "Coach interactions work end-to-end"
  artifacts:
    - path: "tests/e2e/test_collaboration.py"
      provides: "Multi-user collaboration E2E tests"
      contains: "test_invite_collaborator"
    - path: "tests/e2e/test_import_flows.py"
      provides: "Content import E2E tests"
      contains: "test_paste_import"
    - path: "tests/e2e/test_error_recovery.py"
      provides: "Error handling E2E tests"
      contains: "test_retry_on_server_error"
  key_links:
    - from: "tests/e2e/test_collaboration.py"
      to: "tests/e2e/conftest.py"
      via: "second_user fixture"
      pattern: "second_user"
---

<objective>
Create comprehensive E2E tests for collaboration, import flows, error recovery, and coach interactions.

Purpose: Verify all major feature areas work correctly in a real browser environment, catching integration issues.
Output: E2E test suite covering collaboration, import, error recovery, and coach features.
</objective>

<execution_context>
@C:\Users\gpt30\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\gpt30\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-integration-polish/13-CONTEXT.md
@tests/e2e/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create collaboration E2E tests</name>
  <files>tests/e2e/test_collaboration.py, tests/e2e/conftest.py</files>
  <action>
Update tests/e2e/conftest.py with additional fixtures:

1. @pytest.fixture second_user(page, live_server):
   - Register and login second user
   - Return page with second user session

2. @pytest.fixture course_with_collaborator(page, second_user, live_server):
   - First user creates course
   - First user invites second user
   - Second user accepts invitation
   - Return course_id

Create tests/e2e/test_collaboration.py:

1. test_invite_collaborator_by_email(page, mock_ai_responses):
   - Create course
   - Open collaboration modal
   - Enter collaborator email
   - Select role (Designer)
   - Submit invitation
   - Verify invitation appears in pending list

2. test_accept_invitation(page, second_user, live_server):
   - First user creates course and invites second
   - Second user visits invitation link
   - Accept invitation
   - Verify course appears in second user's dashboard

3. test_role_permissions_enforced(page, course_with_collaborator):
   - Second user (Designer) can edit content
   - Second user cannot delete course
   - Verify permission error shown for forbidden action

4. test_comment_on_activity(page, course_with_collaborator):
   - Open activity in studio
   - Open comments panel
   - Add comment
   - Verify comment appears
   - Second user can see comment

5. test_activity_feed_shows_changes(page, course_with_collaborator):
   - First user makes edit
   - Second user views activity feed
   - Verify edit appears in feed
  </action>
  <verify>pytest tests/e2e/test_collaboration.py -v</verify>
  <done>Collaboration E2E tests cover invitation, acceptance, permissions, comments, and activity feed</done>
</task>

<task type="auto">
  <name>Task 2: Create import flow and error recovery E2E tests</name>
  <files>tests/e2e/test_import_flows.py, tests/e2e/test_error_recovery.py</files>
  <action>
Create tests/e2e/test_import_flows.py:

1. test_paste_json_import(page, mock_ai_responses):
   - Navigate to import page
   - Paste JSON blueprint in textarea
   - Click import button
   - Verify blueprint preview shown
   - Accept import
   - Verify course structure created

2. test_paste_markdown_import(page, mock_ai_responses):
   - Paste markdown content
   - Verify format detected as markdown
   - Import and verify

3. test_file_upload_import(page, mock_ai_responses):
   - Upload test JSON file
   - Verify file parsed
   - Import and verify

4. test_import_validation_error(page):
   - Paste invalid JSON
   - Verify error message shown
   - No crash, can retry

5. test_import_with_ai_enhancement(page, mock_ai_responses):
   - Paste plain text
   - Enable AI enhancement option
   - Verify AI converts to structured format

Create tests/e2e/test_error_recovery.py:

1. test_retry_on_server_error(page):
   - Mock server to return 503 on first request
   - Trigger action
   - Verify retry happens automatically
   - Second request succeeds
   - User sees success, not error

2. test_timeout_dialog_appears(page):
   - Mock server to delay 35 seconds (beyond 30s save timeout)
   - Trigger save action
   - Verify timeout dialog appears
   - Click "Keep Waiting" extends timeout
   - Eventually succeeds

3. test_cancel_long_operation(page):
   - Start content generation
   - Click cancel button
   - Verify operation cancelled
   - UI returns to stable state

4. test_validation_error_inline(page):
   - Submit form with invalid data
   - Verify inline error appears next to field
   - Fix error, resubmit
   - Verify success
  </action>
  <verify>pytest tests/e2e/test_import_flows.py tests/e2e/test_error_recovery.py -v</verify>
  <done>Import and error recovery E2E tests cover major scenarios</done>
</task>

<task type="auto">
  <name>Task 3: Create coach interaction E2E tests</name>
  <files>tests/e2e/test_coach.py</files>
  <action>
Create tests/e2e/test_coach.py:

1. test_coach_session_start(page, mock_ai_responses):
   - Navigate to coach activity
   - Click "Start Session" button
   - Verify chat interface appears
   - Initial AI greeting displayed

2. test_coach_message_exchange(page, mock_ai_responses):
   - Start coach session
   - Type message in input
   - Click send
   - Verify message appears in chat
   - Verify AI response appears (streaming or complete)

3. test_coach_evaluation_display(page, mock_ai_responses):
   - Complete a coach session (multiple exchanges)
   - End session
   - Verify evaluation modal appears
   - Rubric scores visible
   - Transcript saved

4. test_coach_session_persistence(page, mock_ai_responses):
   - Start session, send message
   - Refresh page
   - Verify session restores from sessionStorage
   - Can continue conversation

5. test_coach_stays_on_topic(page, mock_ai_responses):
   - Mock AI response that includes off-topic detection
   - Send off-topic message
   - Verify AI gently redirects to topic

Mock responses for coach tests:
- Initial greeting based on activity topic
- Socratic response with question
- Evaluation with rubric scores
  </action>
  <verify>pytest tests/e2e/test_coach.py -v</verify>
  <done>Coach E2E tests verify session lifecycle, messaging, evaluation, and persistence</done>
</task>

</tasks>

<verification>
- All E2E tests pass: pytest tests/e2e -v
- Tests complete in reasonable time (<5 min total)
- No flaky tests on repeated runs
- Tests work in headless mode (CI) and headed mode (debugging)
- Mock responses realistic enough to catch integration issues
</verification>

<success_criteria>
- 15+ E2E tests across collaboration, import, error recovery, coach
- All tests use mock AI by default
- Tests cover happy paths and error cases
- Multi-user collaboration tested
- No flaky tests
</success_criteria>

<output>
After completion, create `.planning/phases/13-integration-polish/13-07-SUMMARY.md`
</output>
